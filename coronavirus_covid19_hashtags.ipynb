{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets with Coronavirus/ Covid19 Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "We compute the polarity (and normalized polarity) of tweets containing the hashtags *Coronavirus* and/or *Covid19*.\n",
    "Polarity will be based on vader's polarity scores.\n",
    "\n",
    "Tweet texts will be cleaned by setting all characters to lowercase and removing words with backslash x, stopwords, links, and special characters using simple regex statements. \n",
    "\n",
    "The result will be stored in DataFrame *tweets_df* with the following columns:\n",
    "- timestamp\n",
    "- tweet_text\n",
    "- username\n",
    "- all_hashtags\n",
    "- followers_count\n",
    "- location\n",
    "- clean_text\n",
    "- polarity\n",
    "- normalized_polarity"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed files and libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/april/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing vader lexicon \n",
    "vader_lex = pd.read_csv('vader_lexicon.txt', \n",
    "                   sep='\\t',\n",
    "                   usecols=[0, 1], \n",
    "                   names=['token', 'polarity'],\n",
    "                   index_col='token')\n",
    "\n",
    "# Setting stopwords\n",
    "stop_words = list(set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing tweets\n",
    "csv_file = 'hashtagcoronavirus_covid19.csv'\n",
    "column_name = 'tweet_text'\n",
    "tweets_df = pd.read_csv(csv_file)\n",
    "tweet_text = tweets_df.loc[:, (column_name)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean data and compute both normalized and non-normalized polarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet): \n",
    "    '''\n",
    "    1. Lowercase text\n",
    "    2. Remove words with backslash x\n",
    "    2. Clean tweet text by removing links, special characters using simple regex statements. \n",
    "    3. Remove stopwords\n",
    "    '''\n",
    "\n",
    "    low = tweet.lower()\n",
    "    low_fil = \" \".join(filter(lambda x:x[:2]!='\\\\x', low.split()))\n",
    "    no_punct = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", low_fil).split())\n",
    "    cleaned = \" \".join(filter(lambda x:x not in stop_words, no_punct.split()))\n",
    "    return cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used. But can use instead of manually computing polarity from vader_lexicon.txt as done below\n",
    "\n",
    "def sentiment_scores(sentence): \n",
    "  \n",
    "    # Create a SentimentIntensityAnalyzer object. \n",
    "    sid_obj = SentimentIntensityAnalyzer() \n",
    "  \n",
    "    # polarity_scores method of SentimentIntensityAnalyzer \n",
    "    # object gives a sentiment dictionary. \n",
    "    # which contains pos, neg, neu, and compound scores. \n",
    "    sentiment_dict = sid_obj.polarity_scores(sentence) \n",
    "    return sentiment_dict['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column with cleaned tweet texts\n",
    "for i in range(len(tweet_text)):\n",
    "    cleaned = clean_tweet(tweet_text[i][1:])\n",
    "    tweets_df.at[i, \"clean_text\"] = cleaned\n",
    "    \n",
    "    # Computing normalized polarity using vader's sentiment_scores function\n",
    "    tweets_df.at[i, \"normalized_polarity\"] = sentiment_scores(cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Computing non-normalized polarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting tweets into tidy_format\n",
    "tidy_format = (tweets_df[\"clean_text\"].str.split(expand=True).stack().reset_index(level=1).rename(columns={'level_1': 'num', 0: 'word'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing polarity of each tweet text by summing polarity of each word in text\n",
    "# Polarity of each word based on vader's polarity in vader_lexicon.txt \n",
    "tweets_df['polarity'] = tidy_format.merge(vader_lex, how='left', left_on='word', right_index=True).reset_index().loc[:, ['index', 'polarity']].groupby('index').sum().fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>username</th>\n",
       "      <th>all_hashtags</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>location</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>normalized_polarity</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-14 02:31:35</td>\n",
       "      <td>b'He gets up every day? Hasn\\xe2\\x80\\x99t caug...</td>\n",
       "      <td>b'bigmusicfan71'</td>\n",
       "      <td>['coronavirus', 'COVID19', '25thAmendmentNow']</td>\n",
       "      <td>354</td>\n",
       "      <td>b''</td>\n",
       "      <td>gets every day xe2 x80 x99t caught coronavirus...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-14 02:31:35</td>\n",
       "      <td>b'@Welptheresthat @NorthmanTrader Not when the...</td>\n",
       "      <td>b'GKeeto'</td>\n",
       "      <td>['china', 'ChinaMustExplain', 'ChinaVirus', 'C...</td>\n",
       "      <td>6</td>\n",
       "      <td>b''</td>\n",
       "      <td>product complete chinese made garbage accounts...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2020-04-14 02:31:34</td>\n",
       "      <td>b'Holy \\xf0\\x9f\\x92\\xa9 \\xe2\\x81\\xa6@VanityFai...</td>\n",
       "      <td>b'DrumpfsLies'</td>\n",
       "      <td>['INCOMPETENCEKILLS', 'COVID19', 'coronavirus'...</td>\n",
       "      <td>230</td>\n",
       "      <td>b'California, USA'</td>\n",
       "      <td>holy scorchingly amazing incompetencekills cov...</td>\n",
       "      <td>0.5859</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-14 02:31:32</td>\n",
       "      <td>b'This could be the end of the line for cruise...</td>\n",
       "      <td>b'1petermartin'</td>\n",
       "      <td>['COVID19', 'coronavirus', 'ausecon', 'auspol']</td>\n",
       "      <td>32382</td>\n",
       "      <td>b''</td>\n",
       "      <td>could end line cruise ships covid19 coronaviru...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2020-04-14 02:31:22</td>\n",
       "      <td>b'Dear @CNN,  Can you sincerely claim @realDon...</td>\n",
       "      <td>b'WarmMonkey'</td>\n",
       "      <td>['coronavirus', 'COVID19']</td>\n",
       "      <td>651</td>\n",
       "      <td>b'Out of The Closet'</td>\n",
       "      <td>dear sincerely claim handling coronavirus cris...</td>\n",
       "      <td>0.6584</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>2020-04-14 01:34:17</td>\n",
       "      <td>b'@JimWTAE @WTAE And here is a third Smithfiel...</td>\n",
       "      <td>b'realhumanrights'</td>\n",
       "      <td>['Wisconsin', 'Cudahy', 'COVID19', 'coronaviru...</td>\n",
       "      <td>2853</td>\n",
       "      <td>b'Washington DC'</td>\n",
       "      <td>third smithfield food plant wisconsin cudahy 2...</td>\n",
       "      <td>0.5574</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>2020-04-14 01:34:15</td>\n",
       "      <td>b'#TruthBeTold  Abso-fucking-lutly!!!  #Heartb...</td>\n",
       "      <td>b'AltBadDude'</td>\n",
       "      <td>['TruthBeTold', 'Heartbreaking', 'trumpsameric...</td>\n",
       "      <td>1308</td>\n",
       "      <td>b'Maryland, USA'</td>\n",
       "      <td>truthbetold abso fucking lutly heartbreaking l...</td>\n",
       "      <td>-0.5829</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>2020-04-14 01:34:15</td>\n",
       "      <td>b'Trump assembles his crew of X-Men to save us...</td>\n",
       "      <td>b'BoneKnightmare'</td>\n",
       "      <td>['EndOfDays', 'apocalypse2020', 'COVID19', 'co...</td>\n",
       "      <td>3760</td>\n",
       "      <td>b'Parts Unknown'</td>\n",
       "      <td>trump assembles crew x men save us doomed endo...</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>2020-04-14 01:34:14</td>\n",
       "      <td>b'A shameful incident of Jaunpur, this is how ...</td>\n",
       "      <td>b'itemads'</td>\n",
       "      <td>['CoronaVirus', 'CoronaVirusPandemic', 'Corona...</td>\n",
       "      <td>63</td>\n",
       "      <td>b'Jeddah'</td>\n",
       "      <td>shameful incident jaunpur misuse power happens...</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>2020-04-14 01:34:13</td>\n",
       "      <td>b'\\xf0\\x9f\\x94\\xa5FACT: CASES NOT DEATHS R HIG...</td>\n",
       "      <td>b'SleepyAddicts'</td>\n",
       "      <td>['coronavirus', 'COVID19', 'WHO', 'CDC', 'viru...</td>\n",
       "      <td>4150</td>\n",
       "      <td>b'Seattle'</td>\n",
       "      <td>xf0 x9f x94 xa5fact cases deaths r high 118k d...</td>\n",
       "      <td>-0.6124</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               timestamp                                         tweet_text  \\\n",
       "0    2020-04-14 02:31:35  b'He gets up every day? Hasn\\xe2\\x80\\x99t caug...   \n",
       "1    2020-04-14 02:31:35  b'@Welptheresthat @NorthmanTrader Not when the...   \n",
       "2    2020-04-14 02:31:34  b'Holy \\xf0\\x9f\\x92\\xa9 \\xe2\\x81\\xa6@VanityFai...   \n",
       "3    2020-04-14 02:31:32  b'This could be the end of the line for cruise...   \n",
       "4    2020-04-14 02:31:22  b'Dear @CNN,  Can you sincerely claim @realDon...   \n",
       "..                   ...                                                ...   \n",
       "995  2020-04-14 01:34:17  b'@JimWTAE @WTAE And here is a third Smithfiel...   \n",
       "996  2020-04-14 01:34:15  b'#TruthBeTold  Abso-fucking-lutly!!!  #Heartb...   \n",
       "997  2020-04-14 01:34:15  b'Trump assembles his crew of X-Men to save us...   \n",
       "998  2020-04-14 01:34:14  b'A shameful incident of Jaunpur, this is how ...   \n",
       "999  2020-04-14 01:34:13  b'\\xf0\\x9f\\x94\\xa5FACT: CASES NOT DEATHS R HIG...   \n",
       "\n",
       "               username                                       all_hashtags  \\\n",
       "0      b'bigmusicfan71'     ['coronavirus', 'COVID19', '25thAmendmentNow']   \n",
       "1             b'GKeeto'  ['china', 'ChinaMustExplain', 'ChinaVirus', 'C...   \n",
       "2        b'DrumpfsLies'  ['INCOMPETENCEKILLS', 'COVID19', 'coronavirus'...   \n",
       "3       b'1petermartin'    ['COVID19', 'coronavirus', 'ausecon', 'auspol']   \n",
       "4         b'WarmMonkey'                         ['coronavirus', 'COVID19']   \n",
       "..                  ...                                                ...   \n",
       "995  b'realhumanrights'  ['Wisconsin', 'Cudahy', 'COVID19', 'coronaviru...   \n",
       "996       b'AltBadDude'  ['TruthBeTold', 'Heartbreaking', 'trumpsameric...   \n",
       "997   b'BoneKnightmare'  ['EndOfDays', 'apocalypse2020', 'COVID19', 'co...   \n",
       "998          b'itemads'  ['CoronaVirus', 'CoronaVirusPandemic', 'Corona...   \n",
       "999    b'SleepyAddicts'  ['coronavirus', 'COVID19', 'WHO', 'CDC', 'viru...   \n",
       "\n",
       "     followers_count              location  \\\n",
       "0                354                   b''   \n",
       "1                  6                   b''   \n",
       "2                230    b'California, USA'   \n",
       "3              32382                   b''   \n",
       "4                651  b'Out of The Closet'   \n",
       "..               ...                   ...   \n",
       "995             2853      b'Washington DC'   \n",
       "996             1308      b'Maryland, USA'   \n",
       "997             3760      b'Parts Unknown'   \n",
       "998               63             b'Jeddah'   \n",
       "999             4150            b'Seattle'   \n",
       "\n",
       "                                            clean_text  normalized_polarity  \\\n",
       "0    gets every day xe2 x80 x99t caught coronavirus...               0.0000   \n",
       "1    product complete chinese made garbage accounts...               0.0000   \n",
       "2    holy scorchingly amazing incompetencekills cov...               0.5859   \n",
       "3    could end line cruise ships covid19 coronaviru...               0.0000   \n",
       "4    dear sincerely claim handling coronavirus cris...               0.6584   \n",
       "..                                                 ...                  ...   \n",
       "995  third smithfield food plant wisconsin cudahy 2...               0.5574   \n",
       "996  truthbetold abso fucking lutly heartbreaking l...              -0.5829   \n",
       "997  trump assembles crew x men save us doomed endo...              -0.2500   \n",
       "998  shameful incident jaunpur misuse power happens...              -0.4939   \n",
       "999  xf0 x9f x94 xa5fact cases deaths r high 118k d...              -0.6124   \n",
       "\n",
       "     polarity  \n",
       "0         0.0  \n",
       "1         0.0  \n",
       "2         2.8  \n",
       "3         0.0  \n",
       "4         1.3  \n",
       "..        ...  \n",
       "995       2.6  \n",
       "996      -2.5  \n",
       "997      -1.0  \n",
       "998      -2.2  \n",
       "999      -3.0  \n",
       "\n",
       "[1000 rows x 9 columns]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Updated tweets DataFrame with additional clean_text, polarity, and normalized_polarity columns\n",
    "tweets_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
